{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0W9dzx081Gk",
        "outputId": "7d2878c4-5225-4402-f451-7e44b72b6cd7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "PyTorch GPU matmul time: 0.0008 seconds\n",
            "Manual GPU matmul (tensor ops) time: 0.0360 seconds\n",
            "Difference between results: 15814.509765625\n"
          ]
        }
      ],
      "source": [
        "# Day 52 - Matrix Multiplication on GPU (PyTorch)\n",
        "\n",
        "import torch\n",
        "import time\n",
        "\n",
        "# Check GPU\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Matrix sizes\n",
        "N = 500  # Reduced size to avoid OutOfMemoryError\n",
        "A = torch.randn(N, N, device=device)\n",
        "B = torch.randn(N, N, device=device)\n",
        "\n",
        "# ---------------- Built-in PyTorch GPU multiplication ----------------\n",
        "start = time.time()\n",
        "C = torch.matmul(A, B)  # GPU accelerated\n",
        "torch.cuda.synchronize() if device == \"cuda\" else None\n",
        "end = time.time()\n",
        "\n",
        "print(f\"PyTorch GPU matmul time: {end - start:.4f} seconds\")\n",
        "\n",
        "# ---------------- Manual Element-wise Multiplication Simulation ----------------\n",
        "# (not as fast as torch.matmul, but shows GPU tensor operations)\n",
        "start = time.time()\n",
        "C_manual = (A.unsqueeze(2) * B.t().unsqueeze(0)).sum(dim=1)\n",
        "torch.cuda.synchronize() if device == \"cuda\" else None\n",
        "end = time.time()\n",
        "\n",
        "print(f\"Manual GPU matmul (tensor ops) time: {end - start:.4f} seconds\")\n",
        "\n",
        "# Validate correctness\n",
        "print(\"Difference between results:\", torch.norm(C - C_manual).item())"
      ]
    }
  ]
}